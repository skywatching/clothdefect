{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanggw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.preprocessing.image\n",
    "import keras.backend as K\n",
    "#from keras.applications.Detect import ResNet50, preprocess_input\n",
    "#from keras.applications.xception import Xception, preprocess_input\n",
    "#from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras import optimizers \n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from pixel_shuffler import PixelShuffler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Defect_class = [\n",
    "    'defect_1',\n",
    "    'defect_2',\n",
    "    'defect_3',\n",
    "    'defect_4',\n",
    "    'defect_5',\n",
    "    'defect_6',\n",
    "    'defect_7',\n",
    "    'defect_8',\n",
    "    'defect_9',\n",
    "    'defect_10',\n",
    "    'norm',\n",
    "]\n",
    "IMAGE_SHAPE = (640,640,3)\n",
    "ENCODER_DIM = 3200\n",
    "BATCH_SIZE = 16\n",
    "CLASS_COUNT = 11\n",
    "BASE_DIR = './logs'\n",
    "\n",
    "ENCODER_WEIGHT = './logs/encoder_20180828T1034.h5'\n",
    "CLASSFY_WEIGHT = './logs/classfy_20180828T1034.h5'\n",
    "\n",
    "\n",
    "EPOCH_INIT = 0\n",
    "EPOCH_TOTAL = 4000\n",
    "EPOCH_STEP = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import logging\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "\n",
    "class ImgGenerator(object):\n",
    "    def __init__(self, samples, class_mapping, batch_size, augment=True, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.samples = samples\n",
    "        self.class_mapping = class_mapping\n",
    "        self.classcnt = len(self.class_mapping.keys())\n",
    "        print(\"Class count:{}\".format(self.classcnt))\n",
    "        self.encoder = encoder\n",
    "        self.encoder.load_weights(ENCODER_WEIGHT)\n",
    "        if self.augment:\n",
    "            self.augment_prepare()\n",
    "\n",
    "    def augment_prepare(self):\n",
    "        ia.seed(20180827)\n",
    "        self.ia_seq = iaa.Sequential(\n",
    "            [\n",
    "                iaa.Affine(rotate=(-10, 10), shear=(-5, 5)),\n",
    "            ],\n",
    "            random_order=True,\n",
    "        )\n",
    "    def augment_image(self, batch_images):\n",
    "        seq_det = self.ia_seq.to_deterministic()\n",
    "        images_aug = seq_det.augment_images(batch_images)\n",
    "        return images_aug\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        filepath = self.samples[image_id]\n",
    "        classid = self.class_mapping[filepath.split('/')[-2]]\n",
    "        img = skimage.io.imread(filepath)\n",
    "        if img.ndim != 3:\n",
    "            img = skimage.color.gray2rgb(img)\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        #print(\"Imgpath:{}\\n label:{}\".format(filepath, classid))\n",
    "        return img, classid\n",
    "\n",
    "    def flow(self):\n",
    "        b = 0\n",
    "        image_index = -1\n",
    "        image_ids = np.arange(len(self.samples))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                image_index = (image_index + 1) % len(image_ids)\n",
    "                if self.shuffle and image_index == 0:\n",
    "                    np.random.shuffle(image_ids)\n",
    "\n",
    "                image_id = image_ids[image_index]\n",
    "                img, classid = self.load_image(image_id)\n",
    "\n",
    "                if self.augment:\n",
    "                    img = self.augment_image(batch_images)\n",
    "                img = preprocess_input(img)\n",
    "                if b == 0:\n",
    "                    #batch_images = np.zeros((self.batch_size,) + img.shape, dtype=np.float32)\n",
    "                    batch_images = np.zeros((self.batch_size,) + (20, 20, 128*12), dtype=np.float32)\n",
    "                    batch_labels = np.zeros((self.batch_size, self.classcnt), dtype=np.int32)\n",
    "               \n",
    "                block_images = np.zeros((12,) + (640, 640, 3), dtype=np.float32)\n",
    "                for i in range(3):\n",
    "                    for j in range(4):\n",
    "                        block_images[i*4+j] = img[i*640:(i+1)*640, j*640:(j+1)*640, :]\n",
    "                preds = self.encoder.predict_on_batch(block_images)\n",
    "                preds = np.reshape(preds, (20, 20, 128*12))\n",
    "\n",
    "                batch_images[b] = preds\n",
    "                batch_labels[b, classid] = 1\n",
    "\n",
    "                b += 1\n",
    "                if b >= self.batch_size:\n",
    "                    inputs = batch_images\n",
    "                    outputs = batch_images   #batch_labels\n",
    "                    yield inputs, outputs\n",
    "                    b = 0\n",
    "            except:\n",
    "                logging.exception(\"Error for image {}\".format(image_index))\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'defect_1': 0, 'defect_2': 1, 'defect_3': 2, 'defect_4': 3, 'defect_5': 4, 'defect_6': 5, 'defect_7': 6, 'defect_8': 7, 'defect_9': 8, 'defect_10': 9, 'norm': 10}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {defect:classid for classid, defect in enumerate(Defect_class)}\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_data = json.load(open('samples.json'))\n",
    "train_files = samples_data['train']\n",
    "valid_files = samples_data['valid']\n",
    "#print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(filters):\n",
    "    def block(x):\n",
    "        x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def upscale(filters):\n",
    "    def block(x):\n",
    "        x = Conv2D(filters*4, kernel_size=3, padding='same')(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "        x = PixelShuffler()(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def Encoder():\n",
    "    input_ = Input(shape=IMAGE_SHAPE)\n",
    "    x = input_\n",
    "\n",
    "    x = conv(128)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = conv(256)(x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = conv(512)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = conv(1024)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(ENCODER_DIM)(x)\n",
    "    #x = Dense(4*4*256)(x)\n",
    "    x = Reshape((10,10,32))(x)\n",
    "    x = upscale(128)(x)\n",
    "    return Model(input_, x)\n",
    "\n",
    "def Decoder():\n",
    "    input_ = Input(shape=(20,20,128))\n",
    "    x = input_\n",
    "    x = upscale(256)(x)\n",
    "    x = upscale(128)(x)\n",
    "    x = upscale(128)(x)\n",
    "    x = upscale(64)(x)\n",
    "    x = upscale(64)(x)\n",
    "    x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)\n",
    "    return Model(input_, x)\n",
    "\n",
    "def Classfy():\n",
    "    input_ = Input(shape=(20, 20, 128*12))\n",
    "    x = input_\n",
    "    x = Conv2D(1024, (3, 3), strides=(2, 2), name='gw_conv01')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), strides=(2, 2), name='gw_conv02')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), strides=(2, 2), name='gw_conv03')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Flatten()(x)\n",
    " \n",
    "    x = Dense(CLASS_COUNT, activation='softmax', name='predict')(x)\n",
    "    model = Model(inputs=input_, outputs=x)\n",
    "    return model\n",
    "\n",
    "def detect_model():\n",
    "    return classfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhanggw/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1259: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "classfy = Classfy()\n",
    "#print(encoder.summary())\n",
    "#print(decoder.summary())\n",
    "#print(classfy.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def FScore2(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSaver(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        dt ='{:%Y%m%dT%H%M}'.format(datetime.datetime.now())\n",
    "        #encoder.save_weights(\"./logs/encoder_{:%.4d}_{}.h5\".format(epoch, dt))\n",
    "        classfy.save_weights(\"./logs/classfy_{}.h5\".format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count:11\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'logs/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-de08d07cd3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImgGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImgGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-286ce8b44e40>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samples, class_mapping, batch_size, augment, shuffle)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class count:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasscnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"logs/encoder.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'logs/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "train_generator = ImgGenerator(train_files, class_mapping, BATCH_SIZE)\n",
    "valid_generator = ImgGenerator(valid_files, class_mapping, BATCH_SIZE, augment=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectmodel = detect_model()\n",
    "detectmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy', precision, FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(BASE_DIR, os.path.splitext(os.path.basename(__file__))[0])\n",
    "checkout_path = os.path.join(log_dir, \"{}_*epoch*.h5\".format('classfy'))\n",
    "checkout_path = checkout_path.replace(\"*epoch*\", \"{epoch:04d}-{val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfiles = glob.glob(os.path.join(log_dir, \"./{}_*.h5\".format('classfy'))\n",
    "modelfiles = sorted(modelfiles)\n",
    "if len(modelfiles) > 0:\n",
    "    modelfile = modelfiles[-1]\n",
    "    print(\"Load Weight: {}\".format(modelfile))\n",
    "    detectmodel.load_weights(modelfile, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    TensorBoard(log_dir=log_dir, write_images=False),\n",
    "    ModelCheckpoint(checkout_path, monitor='acc', verbose=1, save_weights_only=True, save_best_only=False),\n",
    "    #EarlyStopping(monitor='acc', patience=50000, verbose=1)\n",
    "    WeightSaver(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n",
    "history_tl = self.model.fit_generator(\n",
    "                generator = train_generator.flow(),\n",
    "                initial_epoch = EPOCH_INIT,\n",
    "                epochs = EPOCH_TOTAL,\n",
    "                steps_per_epoch = EPOCH_STEP,\n",
    "                validation_data = valid_generator.flow(),\n",
    "                validation_steps = valid_generator.len()//BATCH_SIZE,\n",
    "                verbose = 1,\n",
    "                callbacks = callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
